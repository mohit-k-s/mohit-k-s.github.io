<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Distributed-Systems on Mohit&#39;s Page</title>
    <link>http://localhost:1313/tags/distributed-systems/</link>
    <description>Recent content in Distributed-Systems on Mohit&#39;s Page</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <copyright>Mohit Kumar</copyright>
    <lastBuildDate>Sun, 07 Dec 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/distributed-systems/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>WalJet: Building a High-Performance CDC Pipeline</title>
      <link>http://localhost:1313/blog/2025/waljet/</link>
      <pubDate>Sun, 07 Dec 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/2025/waljet/</guid>
      <description>&lt;p&gt;Change Data Capture (CDC) sounds simple on paper: take database changes, stream them somewhere else. How hard could it be?&lt;/p&gt;&#xA;&lt;p&gt;Very hard.&lt;/p&gt;&#xA;&lt;p&gt;Here&amp;rsquo;s what I hacked away when i was bored at work.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-problem&#34;&gt;The Problem&lt;/h2&gt;&#xA;&lt;p&gt;Modern applications often need to react to database changes in real-time. Whether it&amp;rsquo;s updating a cache, triggering workflows, or syncing data across services, you need a reliable way to capture and stream database changes.&lt;/p&gt;&#xA;&lt;p&gt;Postgres has a powerful feature called Write-Ahead Logging (WAL) that records every change before it&amp;rsquo;s applied. The challenge is turning that low-level stream into something useful.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Change Data Capture (CDC) sounds simple on paper: take database changes, stream them somewhere else. How hard could it be?</p>
<p>Very hard.</p>
<p>Here&rsquo;s what I hacked away when i was bored at work.</p>
<h2 id="the-problem">The Problem</h2>
<p>Modern applications often need to react to database changes in real-time. Whether it&rsquo;s updating a cache, triggering workflows, or syncing data across services, you need a reliable way to capture and stream database changes.</p>
<p>Postgres has a powerful feature called Write-Ahead Logging (WAL) that records every change before it&rsquo;s applied. The challenge is turning that low-level stream into something useful.</p>
<h2 id="architecture">Architecture</h2>
<p>WalJet&rsquo;s architecture is straightforward but carefully designed:</p>
<img src="../images/waljet_arch.png" alt="Waljet architecture" width="600"/>
<p><strong>Key components:</strong></p>
<ol>
<li><strong>WAL Listener</strong>: Connects to Postgres using logical replication protocol (<code>pgoutput</code>)</li>
<li><strong>Decoder</strong>: Parses binary WAL messages into structured change events</li>
<li><strong>Encoder Pool</strong>: Parallel workers that serialize events to Protobuf</li>
<li><strong>Publisher Pool</strong>: Batches and publishes events to Redis Streams</li>
<li><strong>Checkpoint Manager</strong>: Tracks replication progress with dual storage (Redis + file)</li>
</ol>
<h2 id="why-this-stack">Why This Stack?</h2>
<p><strong>Postgres WAL + pglogrepl</strong>: Direct access to the write-ahead log using Go&rsquo;s <code>pglogrepl</code> library. No JVM overhead, no Kafka Connect complexity.</p>
<p><strong>Protobuf encoding</strong>: Smaller payloads, type safety, and faster serialization than JSON. When you&rsquo;re processing thousands of events per second, this matters.</p>
<p><strong>Redis Streams</strong>: Ordered delivery, consumer groups, and sub-millisecond latency. Perfect for real-time event streaming without the operational overhead of Kafka.</p>
<p>The entire pipeline is designed around one goal: get database changes to downstream consumers as fast as possible, with minimal resource usage.</p>
<p>At no point this is a debezium replacer , debezium is a much more complex system, waljet is just a simple hack to get things done.</p>
<h2 id="the-tricky-parts">The Tricky Parts</h2>
<h3 id="graceful-shutdown">Graceful Shutdown</h3>
<p>This one caught me off guard. You can&rsquo;t just kill a CDC process—you&rsquo;ll leak replication slots and lose checkpoint data.</p>





<pre tabindex="0"><code>1. Stop accepting new events
2. Close event channels
3. Wait for workers to finish (flush batches)
4. Save final checkpoint (Redis + file)
5. Close replication connection
6. Open regular connection
7. Drop replication slot
8. Close regular connection
9. Close Redis connection</code></pre><p>The gotcha? You can&rsquo;t drop a replication slot while you&rsquo;re still using the replication connection. You need to:</p>
<ol>
<li>Close the replication connection</li>
<li>Open a regular Postgres connection</li>
<li>Drop the slot</li>
<li>Close the regular connection</li>
</ol>
<p>Miss this, and you leak storage in Postgres. The WAL files pile up, and eventually, you run out of disk space.</p>
<h3 id="checkpoint-durability">Checkpoint Durability</h3>
<p>When WalJet crashes (and it will), where do you resume? You need to track the last processed Log Sequence Number (LSN).</p>
<p>I went with a dual checkpoint system:</p>
<ul>
<li><strong>Primary</strong>: Redis key (<code>waljet:checkpoint:waljet_slot</code>)</li>
<li><strong>Backup</strong>: Local file (<code>.waljet_checkpoint_waljet_slot</code>)</li>
</ul>
<p>Why both? If Redis restarts, you still have the local file. If the container dies, Redis has the checkpoint. On startup, WalJet checks both and uses whichever is more recent.</p>
<p>Simple, but it works.</p>
<h2 id="why-build-this">Why Build This?</h2>
<p>The idea was simple: what if you could react to database changes in real-time without the complexity of Debezium or Kafka?</p>
<p>WalJet is designed for use cases where you need fast CDC with minimal infrastructure:</p>
<ul>
<li><strong>Cache invalidation</strong>: Update Redis/Memcached the moment data changes</li>
<li><strong>Webhook triggers</strong>: Call external APIs when specific rows are modified</li>
<li><strong>Event-driven architectures</strong>: Stream changes to downstream services</li>
</ul>
<p>It&rsquo;s not trying to replace Kafka or Debezium for large-scale data pipelines. It&rsquo;s for when you need something lightweight, fast, and easy to deploy.</p>
<h2 id="benchmark">Benchmark</h2>
<p>I ran a 5-minute benchmark comparing WalJet with Debezium under identical conditions:</p>
<table>
  <thead>
      <tr>
          <th>Metric</th>
          <th>Debezium</th>
          <th>WalJet</th>
          <th>Improvement</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Events/sec</strong></td>
          <td>92.32</td>
          <td>95.07</td>
          <td>+3%</td>
      </tr>
      <tr>
          <td><strong>P50 Latency</strong></td>
          <td>541.44ms</td>
          <td>23.44ms</td>
          <td><strong>23x faster</strong></td>
      </tr>
      <tr>
          <td><strong>P95 Latency</strong></td>
          <td>871.11ms</td>
          <td>50.16ms</td>
          <td><strong>17x faster</strong></td>
      </tr>
      <tr>
          <td><strong>P99 Latency</strong></td>
          <td>952.98ms</td>
          <td>53.15ms</td>
          <td><strong>18x faster</strong></td>
      </tr>
      <tr>
          <td><strong>Avg Latency</strong></td>
          <td>541.08ms</td>
          <td>25.17ms</td>
          <td><strong>21x faster</strong></td>
      </tr>
      <tr>
          <td><strong>Max Latency</strong></td>
          <td>1131.87ms</td>
          <td>171.33ms</td>
          <td><strong>6.6x faster</strong></td>
      </tr>
      <tr>
          <td><strong>Events Lost</strong></td>
          <td>0</td>
          <td>0</td>
          <td>✓</td>
      </tr>
  </tbody>
</table>
<p>The throughput is similar, but latency tells the real story. WalJet&rsquo;s P99 latency is 53ms compared to Debezium&rsquo;s 953ms—nearly 20x faster.</p>
<blockquote>
<p>&ldquo;When you&rsquo;re invalidating a cache or triggering a webhook, waiting 950ms vs 50ms is the difference between a system that feels instant and one that feels sluggish.&rdquo;</p>
<p>— Me, after running this benchmark</p></blockquote>
<p>Remember <a href="https://letterboxd.com/film/the-hummingbird-project/"><em>The Hummingbird Project</em></a>? The movie where they&rsquo;re trying to build a fiber optic cable in a straight line from Kansas to New Jersey just to shave off a few milliseconds for high-frequency trading. Every millisecond was worth millions.</p>
<p>WalJet isn&rsquo;t for HFT, but the principle is the same: in systems where you need to react to changes immediately like cache invalidation, real-time webhooks, event-driven architectures—latency isn&rsquo;t just a nice-to-have. It&rsquo;s the whole point.</p>
<h2 id="why-not-open-source-yet">Why Not Open Source (Yet)?</h2>
<p>WalJet started as a fun experiment—something I hacked for fun,  It works, the benchmarks are promising, but it&rsquo;s not production-ready in the way an OSS project should be.</p>
<p>There&rsquo;s still work to do:</p>
<ul>
<li><strong>More performance testing</strong>: The benchmark above is just one scenario. Need to test under different loads, failure modes, and edge cases</li>
<li><strong>Better error handling</strong>: Right now it works for the happy path, but production systems need to handle every unhappy path too</li>
<li><strong>Documentation</strong>: The code needs better docs, examples, and a proper getting-started guide</li>
<li><strong>Battle testing</strong>: It hasn&rsquo;t been run in production long enough to discover all the weird bugs</li>
</ul>
<p>Maybe it&rsquo;ll be open source someday. For now, it&rsquo;s a proof of concept that taught me a lot about Postgres internals and CDC pipelines. And honestly? That was the whole point.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Commmon Distributed Systems Lingo</title>
      <link>http://localhost:1313/blog/2025/distributed_systems_lingo/</link>
      <pubDate>Tue, 29 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/2025/distributed_systems_lingo/</guid>
      <description>&lt;p&gt;There are a few terms that keep popping up when you work with distributed systems. They&amp;rsquo;re often thrown around casually, and it’s easy to nod along without fully understanding them. I’m collecting those here with simple definitions and examples. This list will evolve as I keep learning.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;fencing-token&#34;&gt;Fencing Token&lt;/h2&gt;&#xA;&lt;p&gt;I was reading &lt;a href=&#34;https://avi.im/blag/2024/s3-log/#:~:text=a%20concept%20of-,fencing%20tokens.,-I%E2%80%99ve%20left%20this&#34;&gt;V&amp;rsquo;s blog&lt;/a&gt; and he mentioned fencing token. This word was introduced in Martin&amp;rsquo;s blog &lt;a href=&#34;https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;A &lt;strong&gt;fencing token&lt;/strong&gt; is a number (usually monotonically increasing) that helps prevent &lt;strong&gt;split-brain writes&lt;/strong&gt; or &lt;strong&gt;duplicate actions&lt;/strong&gt; in distributed systems.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>There are a few terms that keep popping up when you work with distributed systems. They&rsquo;re often thrown around casually, and it’s easy to nod along without fully understanding them. I’m collecting those here with simple definitions and examples. This list will evolve as I keep learning.</p>
<hr>
<h2 id="fencing-token">Fencing Token</h2>
<p>I was reading <a href="https://avi.im/blag/2024/s3-log/#:~:text=a%20concept%20of-,fencing%20tokens.,-I%E2%80%99ve%20left%20this">V&rsquo;s blog</a> and he mentioned fencing token. This word was introduced in Martin&rsquo;s blog <a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">here</a>.</p>
<p>A <strong>fencing token</strong> is a number (usually monotonically increasing) that helps prevent <strong>split-brain writes</strong> or <strong>duplicate actions</strong> in distributed systems.</p>
<p>It’s commonly used in <strong>distributed locks</strong>. Here&rsquo;s why:</p>
<p>Let’s say two nodes both believe they hold a lock (due to clock drift or network delays). Without fencing, both might write to a shared resource. With fencing, each action is tagged with a <strong>token</strong> (say, 41 and 42). The system can reject the one with the lower token, assuming it’s stale.</p>
<blockquote>
<p><strong>Only the action with the highest fencing token is considered valid.</strong></p></blockquote>
<p>This way, even if the lock coordination fails, the system can still reject outdated operations.</p>
<hr>
<h2 id="network-partition">Network Partition</h2>
<p>A <strong>network partition</strong> is when a group of nodes in a distributed system can no longer talk to another group — not because the nodes have failed, but because something in the network is blocking communication between them.</p>
<p>Think of it as the system getting split into isolated islands.</p>
<blockquote>
<p><strong>Note:</strong> A partition is about communication failure, not node failure.</p></blockquote>
<h3 id="examples">Examples:</h3>
<ul>
<li>A node can talk to nodes A and B, but not to node C. That’s a network partition.</li>
<li>Someone misconfigures firewall rules between two subnets. That’s a network partition.</li>
<li>NACLs (Network Access Control Lists) are misconfigured to block traffic between nodes.</li>
</ul>
<hr>
]]></content:encoded>
    </item>
  </channel>
</rss>
